{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, BaggingRegressor, GradientBoostingRegressor\n",
    "from ml_metrics import rmsle\n",
    "from sklearn.cross_validation import LabelKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', parse_dates=['datetime'])\n",
    "test = pd.read_csv('test.csv', parse_dates=['datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge train & test\n",
    "Merge train & test into one dataframe. This allow in more flexible and simiple way preprocessing data for both dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all = train.append(test)\n",
    "\n",
    "df_all['count_log'] = np.log( df_all['count'] + 1 )\n",
    "df_all['casual_log'] = np.log( df_all['casual'] + 1 )\n",
    "df_all['registered_log'] = np.log( df_all['registered'] + 1 )\n",
    "\n",
    "df_all['is_test'] = df_all['count'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_features(data):\n",
    "    black_list = ['casual', 'registered', 'count', 'is_test', 'datetime', 'count_log', 'casual_log', 'registered_log']\n",
    "    return [feat for feat in data.columns if feat not in black_list]\n",
    "    \n",
    "def get_X_y(data, target_var='count'):\n",
    "    features = select_features(data)\n",
    "    return data[features].values, data[target_var].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cat_hour(hour):\n",
    "    if 5 >= hour < 10:\n",
    "        return 1#morning\n",
    "    elif 10 >= hour < 17:\n",
    "        return 2#day\n",
    "    elif 17 >= hour < 23:\n",
    "        return 3 #evening\n",
    "    else:\n",
    "        return 4 #night\n",
    "    \n",
    "def feature_engineering(data):\n",
    "    data['year'] = data['datetime'].dt.year\n",
    "    data['diff_year'] = data['year'] - 2010\n",
    "    data['month'] = data['datetime'].dt.month\n",
    "    data['day'] = data['datetime'].dt.day\n",
    "    data['hour'] = data['datetime'].dt.hour\n",
    "    data['minute'] = data['datetime'].dt.minute\n",
    "    data['dayofweek'] = data['datetime'].dt.dayofweek\n",
    "    data['weekofyear'] = data['datetime'].dt.weekofyear\n",
    "    data['weekend'] = data.dayofweek.map(lambda x: int(x in [5,6]) )\n",
    "    data['time_of_day'] = data['hour'].map(cat_hour)\n",
    "    \n",
    "    data['dayofyear'] = data['datetime'].dt.dayofyear\n",
    "    data['day_'] = data[ ['year', 'dayofyear'] ].apply(lambda x: x['dayofyear'] + int(str(x['year'])[-1]) * 365  , axis=1)\n",
    "    \n",
    "    data['rush_hour'] = data['datetime'].apply(lambda i: min([np.fabs(9-i.hour), np.fabs(20-i.hour)]))\n",
    "    data.loc[:,('rush_hour')] = data['datetime'].apply(lambda i: np.fabs(14-i.hour))\n",
    "    data.loc[data['workingday'] != 0].loc[:,('rush_hour')] = 0\n",
    "    \n",
    "    data['holiday'] = data[['month', 'day', 'holiday', 'year']].apply(lambda x: (x['holiday'], 1)[x['year'] == 2012 and x['month'] == 10 and (x['day'] in [30])], axis = 1)\n",
    "    data['holiday'] = data[['month', 'day', 'holiday']].apply(lambda x: (x['holiday'], 1)[x['month'] == 12 and (x['day'] in [24, 26, 31])], axis = 1)\n",
    "    \n",
    "    data['workingday'] = data[['month', 'day', 'workingday']].apply(lambda x: (x['workingday'], 0)[x['month'] == 12 and x['day'] in [24, 31]], axis = 1)\n",
    "    data['peak'] = data[['hour', 'workingday']].apply(lambda x: (0, 1)[(x['workingday'] == 1 and  ( x['hour'] == 8 or 17 <= x['hour'] <= 18 or 12 <= x['hour'] <= 12)) or (x['workingday'] == 0 and  10 <= x['hour'] <= 19)], axis = 1)\n",
    "    data['sticky'] = data[['humidity', 'workingday']].apply(lambda x: (0, 1)[x['workingday'] == 1 and x['humidity'] >= 60], axis = 1)\n",
    "\n",
    "    return data\n",
    "\n",
    "df_all = feature_engineering(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "Tuning & Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('n_fold: ', 0)\n",
      "('n_fold: ', 1)\n",
      "('n_fold: ', 2)\n",
      "score: 0.33141, std-score: 0.01\n"
     ]
    }
   ],
   "source": [
    "def modeling(models, data, n_folds=3): #there're 3 folds\n",
    "    labels = data['month'].values\n",
    "    \n",
    "    scores = []\n",
    "    for n_fold, (train_idx, test_idx) in enumerate(LabelKFold(labels, n_folds=n_folds)):\n",
    "        print(\"n_fold: \", n_fold)\n",
    "        y_pred = np.array([0.] * len(test_idx))\n",
    "        \n",
    "        for weight_for_model, feats, model in models:\n",
    "            X = data[feats].values\n",
    "            \n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_reg_train = data['registered_log'][train_idx].astype('float')\n",
    "            y_cas_train = data['casual_log'][train_idx].astype('float')\n",
    "            y_test = data['count'][test_idx].astype('float')\n",
    "\n",
    "            \n",
    "        \n",
    "            model.fit(X_train, y_reg_train)\n",
    "            y_pred_reg_log = model.predict(X_test)\n",
    "            y_pred_reg = np.exp( y_pred_reg_log ) - 1\n",
    "\n",
    "            model.fit(X_train, y_cas_train)\n",
    "            y_pred_cas_log = model.predict(X_test)\n",
    "            y_pred_cas = np.exp( y_pred_cas_log ) - 1\n",
    "\n",
    "            y_pred +=  weight_for_model * (y_pred_reg + y_pred_cas)\n",
    "            \n",
    "        score = rmsle(y_test, y_pred)\n",
    "        scores.append(score)\n",
    "        \n",
    "    print(\"score: {0}, std-score: {1}\".format( round(np.mean(scores), 5), round(np.std(scores), 4) ))\n",
    "        \n",
    "\n",
    "xgb_params = {'n_estimators':150,  'learning_rate':0.1, 'max_depth':5, 'subsample':0.6, 'colsample_bytree': 0.8}\n",
    "xgb_model = xgb.XGBRegressor(**xgb_params)\n",
    "\n",
    "gbm_params = {'n_estimators': 150, 'max_depth': 5, 'random_state': 0, 'min_samples_leaf' : 10, 'learning_rate': 0.1, 'subsample': 0.7, 'loss': 'ls'}\n",
    "gbm_model = GradientBoostingRegressor(**gbm_params)\n",
    "\n",
    "rf_params = {'n_estimators': 1000, 'max_depth': 15, 'random_state': 0, 'min_samples_split' : 5, 'n_jobs': -1}\n",
    "rf_model = RandomForestRegressor(**rf_params)\n",
    "\n",
    "xgb_feats = ['weather', 'temp', 'atemp', 'humidity', 'windspeed', 'holiday', 'workingday', 'season','hour', 'dayofweek', 'year']\n",
    "gbm_feats = ['weather', 'temp', 'atemp', 'humidity', 'windspeed', 'holiday', 'workingday', 'season','hour', 'dayofweek', 'year']\n",
    "rf_feats = ['weather', 'temp', 'atemp', 'windspeed','workingday', 'season', 'holiday', 'hour', 'dayofweek', 'weekofyear', 'rush_hour', 'peak']\n",
    "\n",
    "models = [\n",
    "    #weight, features, model\n",
    "    #weight in sumary should be equal 1\n",
    "    \n",
    "    (.8 * .7, xgb_feats, xgb_model),\n",
    "    (.8 * .3, gbm_feats, gbm_model),\n",
    "    (.2, rf_feats, rf_model),\n",
    "]\n",
    "\n",
    "modeling(models, df_all[~df_all.is_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feats = ['weather', 'temp', 'atemp', 'humidity', 'windspeed', 'holiday', 'workingday', 'season','hour', 'dayofweek', 'year']\n",
    "xgb_features = feats\n",
    "gbm_features = feats\n",
    "rf_features = ['weather', 'temp', 'atemp', 'windspeed','workingday', 'season', 'holiday', 'hour', 'dayofweek', 'weekofyear', 'rush_hour', 'peak']\n",
    "et_features = rf_features\n",
    "\n",
    "df_train = df_all[~df_all['count'].isnull()]\n",
    "df_test =  df_all[ df_all['count'].isnull()]                 \n",
    "\n",
    "_, y_train_count = get_X_y(df_train, 'count_log')\n",
    "(_, y_train_reg), (_, y_train_cas) = get_X_y(df_train, 'registered_log'), get_X_y(df_train, 'casual_log')\n",
    "\n",
    "gbm_X_train, xgb_X_train = df_train[gbm_features], df_train[xgb_features]\n",
    "rf_X_train, et_X_train = df_train[rf_features], df_train[rf_features]\n",
    "\n",
    "gbm_X_test, xgb_X_test  = df_test[gbm_features], df_test[xgb_features]\n",
    "rf_X_test, et_X_test  = df_test[rf_features], df_test[rf_features]\n",
    "\n",
    "gbm_params = {'n_estimators': 150, 'max_depth': 5, 'random_state': 0, 'min_samples_leaf' : 10, 'learning_rate': 0.1, 'subsample': 0.7, 'loss': 'ls'}\n",
    "rf_params = {'n_estimators': 1000, 'max_depth': 15, 'random_state': 0, 'min_samples_split' : 5, 'n_jobs': -1}\n",
    "xgb_params = {'n_estimators':150,  'learning_rate':0.1, 'max_depth':5, 'subsample':0.6, 'colsample_bytree': 0.8}\n",
    "#et_params = {'n_estimators': 100, 'min_samples_leaf': 5, 'random_state': 0, 'min_samples_split': 2}\n",
    "\n",
    "\n",
    "def predict(X_train, X_test, model):\n",
    "    model.fit(X_train, y_train_count)\n",
    "    y_pred_count_log = model.predict(X_test)\n",
    "    y_pred_count = np.exp( y_pred_count_log ) - 1\n",
    "    \n",
    "    model.fit(X_train, y_train_reg)\n",
    "    y_pred_reg_log = model.predict(X_test)\n",
    "    y_pred_reg = np.exp( y_pred_reg_log ) - 1\n",
    "\n",
    "    model.fit(X_train, y_train_cas)\n",
    "    y_pred_cas_log = model.predict(X_test)\n",
    "    y_pred_cas = np.exp( y_pred_cas_log ) - 1\n",
    "    \n",
    "    return y_pred_reg + y_pred_cas\n",
    "    #return .3*y_pred_count + .7*(y_pred_reg + y_pred_cas)\n",
    "\n",
    "gbm_count = predict(gbm_X_train, gbm_X_test, GradientBoostingRegressor(**gbm_params))\n",
    "rf_count = predict(rf_X_train, rf_X_test, RandomForestRegressor(**rf_params))\n",
    "xgb_count = predict(xgb_X_train, xgb_X_test, xgb.XGBRegressor(**xgb_params))\n",
    "#et_count = predict(et_X_train, et_X_test, ExtraTreesRegressor(**et_params))\n",
    "\n",
    "test['count'] = .2*rf_count + .8*( .3*gbm_count  + .7*xgb_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test[ ['datetime', 'count'] ].to_csv('final_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
